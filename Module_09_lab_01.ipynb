{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO72RN0geCVFuw8wuYhWru8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarang330/_PROJECTS_AND_LABS_SARANG/blob/main/Module_09_lab_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Module 9: Neural Networks\n",
        "\n",
        "Lab 1: Introduction to Multi-Layer Perceptron (MLP)"
      ],
      "metadata": {
        "id": "xXd8JNrOE4de"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# # The following code is used for hiding the warnings and make this notebook clearer.\n",
        "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
        "matplotlib_axes_logger.setLevel('ERROR')"
      ],
      "metadata": {
        "id": "66sQ7B_SE7Hs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Code to plot decision boundary ##\n",
        "\n",
        "def plot_decision_regions(X, y, classifier, method, test_idx=None, resolution=0.02):\n",
        "\n",
        "    # setup marker generator and color map\n",
        "    markers = ('s', 'x', 'o', '^', 'v')\n",
        "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
        "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
        "\n",
        "    # plot the decision surface\n",
        "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
        "                           np.arange(x2_min, x2_max, resolution))\n",
        "    if method == 'numpy':\n",
        "        Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
        "    elif method == 'pytorch':\n",
        "        inp = torch.tensor([xx1.ravel(), xx2.ravel()], dtype=torch.float, requires_grad=False).T\n",
        "        Z = np.array([]).reshape(0,1)\n",
        "        for data in inp:\n",
        "            out = classifier(data)\n",
        "            Z = np.vstack((Z, out.data.numpy()))\n",
        "    else:\n",
        "        print('Not implemented')\n",
        "    Z = Z.reshape(xx1.shape)\n",
        "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
        "    plt.xlim(xx1.min(), xx1.max())\n",
        "    plt.ylim(xx2.min(), xx2.max())\n",
        "\n",
        "    # plot class samples\n",
        "    for idx, cl in enumerate(np.unique(y)):\n",
        "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
        "                    alpha=0.8, c=cmap(idx),\n",
        "                    marker=markers[idx], label=cl)\n",
        "\n",
        "    # highlight test samples\n",
        "    if test_idx:\n",
        "        # plot all samples\n",
        "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
        "\n",
        "        plt.scatter(X_test[:, 0],\n",
        "                    X_test[:, 1],\n",
        "                    c='',\n",
        "                    alpha=1.0,\n",
        "                    linewidths=1,\n",
        "                    marker='o',\n",
        "                    s=55, label='test set')"
      ],
      "metadata": {
        "id": "zYD4pEegFGrT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the input data"
      ],
      "metadata": {
        "id": "JOTKggUTFNob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "X = torch.tensor([[0,0],[0,1], [1,0], [1,1]], dtype=torch.float, requires_grad=False)\n",
        "Y = torch.tensor([0,1,1,0], dtype=torch.float, requires_grad=False)"
      ],
      "metadata": {
        "id": "BCq1mBXUFRRL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Initialize all the layers with learnable parameters\n",
        "        self.fc1 = nn.Linear(2, 2, bias=True)\n",
        "        self.fc2 = nn.Linear(2, 1, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Write the forward pass\n",
        "        # Note that we use a sigmoid activation function here\n",
        "        x = self.fc1(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        x = self.fc2(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "model = Net()"
      ],
      "metadata": {
        "id": "QWJ4diLrFUVL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the weights"
      ],
      "metadata": {
        "id": "Zh5nIS-RFXqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Linear):\n",
        "            # initialize the weight tensor, here we use a normal distribution\n",
        "            m.weight.data.normal_(0, 1)\n",
        "\n",
        "weights_init(model)"
      ],
      "metadata": {
        "id": "Ld_QF6lkFbDS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the loss function"
      ],
      "metadata": {
        "id": "R6OFUhqGFf2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a mean square error loss\n",
        "loss_func = nn.MSELoss()"
      ],
      "metadata": {
        "id": "X66P-rXhFj3e"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define optimizer"
      ],
      "metadata": {
        "id": "qHxBwsgDFomG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "LHN9I97PFp_W"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the training routine"
      ],
      "metadata": {
        "id": "8lilO_fJFwU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5000\n",
        "steps = X.size(0)\n",
        "for i in range(epochs): # iterate over epoch\n",
        "    for j in range(steps): # iterate over sample\n",
        "        # randomly sample the inputs\n",
        "        sample = np.random.randint(X.size(0))\n",
        "        x_var = X[sample]\n",
        "        y_var = Y[sample]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_hat = model(x_var)\n",
        "\n",
        "        loss = loss_func.forward(y_hat[0], y_var)\n",
        "\n",
        "\n",
        "        # BACKPROP! You will see more details about this next week!\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    if i % 500 == 0:\n",
        "        print(\"Epoch: {0}, Loss: {1}, \".format(i, loss.data.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByJYaCW3GFU1",
        "outputId": "7966a406-34e8-4b3a-eb7f-470a4ec36c0e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.24057087302207947, \n",
            "Epoch: 500, Loss: 0.27283477783203125, \n",
            "Epoch: 1000, Loss: 0.2418775111436844, \n",
            "Epoch: 1500, Loss: 0.135736346244812, \n",
            "Epoch: 2000, Loss: 0.23376654088497162, \n",
            "Epoch: 2500, Loss: 0.30232366919517517, \n",
            "Epoch: 3000, Loss: 0.3222898840904236, \n",
            "Epoch: 3500, Loss: 0.18817727267742157, \n",
            "Epoch: 4000, Loss: 0.2225925177335739, \n",
            "Epoch: 4500, Loss: 0.09695084393024445, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the output"
      ],
      "metadata": {
        "id": "mRGMplP7GINF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for data in X:\n",
        "    output = model(data)\n",
        "    print(data, np.round(output.data.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYWoTsfRGLwz",
        "outputId": "ad39b12c-333e-44fe-abb2-889a34b2bb72"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0.]) [0.]\n",
            "tensor([0., 1.]) [1.]\n",
            "tensor([1., 0.]) [0.]\n",
            "tensor([1., 1.]) [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the decision boundary"
      ],
      "metadata": {
        "id": "g5P2ynRCGQfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "plot_decision_regions(X.detach().numpy(), Y.detach().numpy(), model, 'pytorch')\n",
        "plt.xlabel('x-axis')\n",
        "plt.ylabel('y-axis')\n",
        "plt.legend(loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "JjQDH883GRtB",
        "outputId": "87dba51b-abe1-4aaf-d819-f6c352b55889"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-d74ee9bebb86>:18: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
            "  inp = torch.tensor([xx1.ravel(), xx2.ravel()], dtype=torch.float, requires_grad=False).T\n",
            "<ipython-input-2-d74ee9bebb86>:32: UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
            "  plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABDwElEQVR4nO3de3xU9Z3/8XcCuSEmgUIuCAIqAlUkAj/YpF3AgiK4tTza9S5SVKhd/VXEtYWuYtW2FC8FdbHoz1qsYsXuKrJeaBFKUaEol1hqkVWK3EoSKpJwTYCc3x8xQ0Imycxkzvl+zzmv5+MxD8iZM/P9nEvm+873XCbFcRxHAAAA8L1U0wUAAAAgOQh2AAAAAUGwAwAACAiCHQAAQEAQ7AAAAAKCYAcAABAQBDsAAICAINgBAAAERHvTBdiutrZWf//733X66acrJSXFdDkAACBkHMfRgQMH1K1bN6WmtjwmR7Brxd///nf16NHDdBkAACDkdu7cqe7du7c4D8GuFaeffrok6Wc/26nMzGzD1QCAHVavrvu3pMRsHa3xtM7V70qSJpX8r0vv79HC2LZxbavHgKqjR9Vj+vRIJmkJwa4V9YdfMzOzlZVFsAOAVaukUaNMV9G6VauktDRp+HCvGjtNU4Z/JCnLpff3YGE8XWkxsK0ew2I5JYxgBwCIyapVdf/6oY/1tNYvGqsLde69v6sLY+PGtbEmHyDYAQBa5Zc+1vM63Qx1Xi2MjRvXxpp8gmAHAGiRX/pYRuksbiceNtbkIwS7JElNPaG0tGOmy7DGsWNpqq1tZ7oMAG3klz6WUGdxO/FYtcquenyIYNdmjgoKypSXt1+t3FomVGprpYqKXJWVFUji/n+AH9nY70dDqLO4nVjZVo+PEezaqKCgTN267deXvpSn9PQO3MRYdTdSrKk5rPbtKyRJZWWFhisCEC+/9LOEOovbiZVt9fgcwa4NUlNPKC+vLtR17Pgl0+VYJT297nL/48crVFGRx2FZwEf80s8S6ixuJ1a21RMABLs2SEs7ptRUKT29g+lSrJSe3kGpqXXrqbqaYAf4gV/62cCEurAGOsnOmgKAYJcEHH6NjvUC+Isf+tnABLoG70+oQzJxuj8AwBf9LKHO4nbiYWNNAUKwA4CQ80M/S6izuJ142FhTwBDsQuyXv5ynwYN7qUePTF166TBt2PBei/MvWfJblZT0U48emRoxYoDeeusNjyoF4Jb624bZ3M8S6ixuJx421hRAnGNnUOquHUo5crjZ552sDqrtfqYrbS9evEj33jtNDz00X4MGDdNTT83VVVeN0erVW9S1a16T+d97b7W+851r9B//MUuXXPIvevnlFzRx4ni99dYG9e9/vis1AnCPX/pYQp3F7cTDxpoCKsVxHMd0ETarqqpSTk6O5s6tVFZWdqPnMjKOqn//berevbfS0jLjet/UXTuUc9WlSjlyqNl5nKzTVLloqSvh7tJLh6mo6P/oZz/7T0lSbW2tiop66Oab/6++973pTeafPPkqHT58SAsXvhaZNnbsP+m884r08MPzo7Zx7NhR7dq1TZs391Z1dXzrB4B7/NLHBibUebkgNm5cG2vymaojR5QzdaoqKyuVnZ3d4ryM2BmScuSwUo4ckpOWLic9o+nzNdVKOXKoxRG9RNXU1OiDD9bre9+bEZmWmpqq4cNHa926NVFfs27dGt1yy7RG00aOHKM331yc9PoAuMcvfaxn3ywVlFG6+rZs27B+2eEChGBnmJOeIWU2Hc1yJKUcq3GlzX37/qETJ06oa9f8RtO7ds3XJ59E/3CrqCiLOn9FRZkrNQJIPj/0sYEZpWvw/qE89CrZW1fAcfEEAISAH/pYQp3F7cTL1rpCgGAXQp07d1G7du20d295o+l795YrL68g6mvy8grimh+APfzQxxLqLG4nXrbWFRIEuxBKT0/XwIGD9fbbyyPTamtr9fbbyzVkSHHU1wwZUtxofkn64x+XNTs/ADv4oY8l1FncTrxsrStECHYhdcst0/T88/9PL774rP73fzfrrru+q8OHD+nqqydJkm699Qb9+McnL66YPPl2rVixVE888Yg+/vgjPfjgj/TBB+t00023mVoEAK3wQx9LqLO4nXjZWlfIcPGEYSk11Yp2v5mUmmpX2x0//ip99tlePfjgTFVUlOn884v04otLlZdXd4HE7t07lJp6MvcPHVqi+fNf0KxZd+unP/2hzjqrj559djH3sAMs5Yc+1rMagxLovG4rHrbWFUIEO0OcrA5ysk6ru6VJM1e/Olmnycnq4FoNN910W7MjbosXr2wy7fLLr9Dll1/hWj0AksP2PpZROh+0FQ9b6wopgp0htd3PVOWipca+eQJAMNnexxLqfNBWPGytK8QIdgYR2gAkk+19LKHO4nYSYXNtIUawA4AAsPFLBxoi1FncTiJsri3kCHYA4GN+6F8JdRa3kwibawO3OwEAv/JD/0qos7idRNhcGyQxYgcAvuSH/pXbmVjeVrxsrg0RBDsA8Bk/9K+enfNHqPOGzbWhEYIdAPiI7f0rh1590Fa8bK4NTXCOHQD4hO39K6HOB23Fy+baEBXBLqTWrFml66//ugYM6Ka8vBS98cbiVl/z7rsrNWrUIHXvnqGhQ8/Riy8ucL1OAHVs718JdT5oK14214ZmEexC6vDhQzrvvIH62c/mxTT/9u3bdN11l+krX7lIK1aU6jvfmao77rhZK1b8zuVKAdjevxLqEmyn/kREGzes7TsdmsU5dgYdPCgdOSJ17dr0ub17pawsqWNHd9oeNWqsRo0aG/P8zz47X2ee2Vv33/+IJOncc/tr7dp39OSTc/S1r41xp0gA1vevhDqL20mU7fWhRQQ7Qw4elH74Q2n/funhh6W8vJPPVVRI//7vUm6u9NOfuhfu4rFu3RoNHz660bSLLhqju++eaqYgIARs71+5nYnlbSXC9vrQKg7FGnLkSF2o27OnLsRVVNRNrw91e/bUPX/kiMkqT6qoKFPXrvmNpnXtmq8DB6p0xJYigQCxvX8l1FneViJsrw8xIdgZ0rVr3UhdYeHJcPfhhydDXWFh3fPRDtMCCDbb+1fPTg0j1HnH9voQM4KdQXl5jcPd1KmNQ13Dw7Om5eUVaO/e8kbT9u4t1+mnZysrK8tQVUDw2Ny/Njzf35PGRKjzhO31IS4EO8Py8qQf/KDxtB/8wK5QJ0lDhhTr7beXN5r2xz8u05AhxYYqAoLH5v6ViyR80FYibK8PcSPYGVZRIc2e3Xja7Nknz7lzy8GDB7VpU6k2bSqVJO3YsU2bNpVq164dkqQf/3iGbr31hsj8Eyfeou3b/6b77vu+Pv74Iz3zzBN69dWX9J3v3OFuoUBI2Ny/Eup80FYibK8PCSHYGdTwQonCQmnu3Mbn3LkZ7j74YJ1GjbpQo0ZdKEmaOXOaRo26ULNnz5QklZfv0e7dOyLz9+zZWwsXvq4//nGZLrpooH7xi0c0Z87T3OoESAJuZ9a4MUKdB2yvDwlLcRzHMV2EzaqqqpSTk6O5cyuVlZXd6LmMjKPq33+bunfvrbS0zLjed+9e6c47m55Td2rYe+QR/15AcezYUe3atU2bN/dWdXV86wcIC8/OWUtAYK58bdAGoU7214cmqo4cUc7UqaqsrFR2dnaL83IfO0OysuruUyc1vlCi/oKK+vvYcV0CEFyEOgVrlK6+PVs3qkSoCwGCnSEdO9bdfDjaN0/k5dWN1Ln5zRMAzLG9byXUtaE9WzeqZP+Oh6Qg2BnUsWPzwc2vh18BtMz2vpXbmVjeVqL8UCOSgmAHAB6xuW/lIgkftJUoP9SIpOGqWADwgM19K6HOB20lyg81IqkIdknAhcXRsV6AOjb3rYQ6H7TVVn6oEUlDsGuDY8fSVFsr1dQcNl2KlWpqDqu2tm49AWFlc/9PqPNBW21h+8UccAXn2LVBbW07VVTkqn37ujsJp6d3UEpKiuGqzHMcRzU1h/XZZxWqqMhVbW070yUBRtjc/wfmytcGbRDqGiDUhRbBro3KygokScePVyiV8c+I2lqpoiI3sn6AsLG5/w9cqPPydiaSnRu1ofo6EUoEuzZLUVlZoSoq8pSWdsx0MdaoO0zNSB3Cyeb+PzChzsQ96rxsL1F+qROuIdglSW1tO1VXE2SAsLO5XyXU+aS9RPmlTriKYAcASWJzv8qNh33SXqL8UidcR7ADgCSwtV/lylcftZcov9QJT3C6PwC0ka39KqHOR+0lyi91wjOM2AFAG9jarxLq2tiebRs0Glt3PhhFsAOABNnarwbmIokGbRDqmuGnWuEJXx2KXbVqlb7+9a+rW7duSklJ0eLFi1ucf+XKlUpJSWnyKCsr86ZgAIFFqAtYqFu1yl+hzk+1wlO+CnaHDh3SwIEDNW/evLhet2XLFu3ZsyfyyMvLc6lCAGFAqAtgqPOqrWQg1KEFvjoUO3bsWI0dOzbu1+Xl5Sk3Nzf5BQEIHVszQOBCHRdJRMe3SqAVvhqxS1RRUZEKCwt18cUX69133zVdDgCfsjUDBCbUeX041NYN2hy/1QsjfDViF6/CwkLNnz9fQ4YMUXV1tZ5++mmNHDlSa9eu1aBBg6K+prq6WtXV1ZGfq6qqvCoXgMVs7VO58bBP2msrv9ULYwId7Pr27au+fftGfi4pKdHWrVs1Z84cPffcc1FfM2vWLN13331elQjAB2w8pYnbmfiovbbyW70wKhSHYhsaOnSoPvnkk2afnzFjhiorKyOPnTt3elgdANsQ6gh1RvmtXhgX6BG7aEpLS1VYWNjs8xkZGcrIyPCwIgC2ItQR6qzgt3phlK+C3cGDBxuNtm3btk2lpaXq3LmzzjzzTM2YMUO7d+/Wr3/9a0nS3Llz1bt3b5133nk6evSonn76aa1YsUK///3vTS0CAJ8IdagL2u1MTLSXDDbuhLCer4LdunXrdNFFF0V+njZtmiRp4sSJWrBggfbs2aMdO3ZEnq+pqdGdd96p3bt3q0OHDrrgggv01ltvNXoPADiVjf0poc5H7SUDtzVBglIcx3FMF2Gzqqoq5eTkaO7cSmVlZZsuB4CLbO3/CXU+ai8Z/FgzXFV15Ihypk5VZWWlsrNbziKhu3gCAKKxtS8l1PmovWTwY82wCsEOQOjZ2pcS6nzUXjL5sWZYw1fn2AFAstna/wcu1Hm5gm3dqK2x8eRO+A7BDkBo2dr/BybUmVjBtm7U1nCxBJKEYAcglGzt//mKMJ+1mQx+rRtWItgBCB0b+1FuPOzDNpPBr3XDWgQ7AKFiYz/qdagL1EUSptpMJr/WDSsR7ACEho39f2DOp2vQBqEuRlwsARdwuxMAoWBj/0+o82GbycLFEnAJwQ5A4NnY/xPqfNhmsvi5dliPYAcg0GzsQwl1Pmwz2fxcO6xGsAMQWDb2/4Q6H7aZTJxXB5dx8USMVq+W0tJan4/fV8AONvb/hDoftplMnFcHDxDsYlRSImVltT6fG7+3fv0MA0yxsf8n1PmwzWTye/3wDYJdkiX7d3bVqvjCIp8ZCDsb+8/AhTqvV66NGzURfq8fvkCws1w8nwOxhEA+VxBkNvb/gfmKsPo2CHXx47w6eIhgFyCtfW60FPz4zIHf2db/8xVhPm43mTivDh4j2IVIc5+NzQU+P3+WIlxs6//5ijAft5tMQVgG+A7BDlE/c6KFPT6bYCPb+s7AnU8nEeraIgjLAF8h2CGqUz+LTg16fFbBBrb1/4Q6H7ebbByChSEEO8QkWtBr7jnAC7b1/4Q6H7ebbEFZDvgSwQ4Jafh5RciD12zrNwl1Pm7XLUFZDvgOwQ5tVv/5xeFaeMG2/p9Q5+N23cAhWBhGsEPSnDqKF6TPatjBtn2KUOfjdt0QpGWBb6WaLgDBNHx48yN5QCJs6zMJdT5u101BWhb4EsEOrjo14AGJsK3/J9T5uF238AEHS3AoFp44NdwF5bMc7rNtnyHU+bhdtwVteeBLjNjBU4zeIR629f+EOh+36ya+CxYWIdjBc4Q7xMK2/r++7ybU+bBdN/FBBstwKBZGcGgWLbFpvwjU975+0YYkQl0yBXGZ4FuM2MEoRu9wKpv6f0Kdz9t1Gx9csBDBDsYR7lDPpv7f0/PpvAp1nhxLjtKuZMdGdUNQlwu+RbCDFfhshE39f6Aukqhvx8SKtWmjJht/icJSBDtYY/hwPivDyqb+n1CXxHYlOzaqW4K8bPAtgh2sQ7gLF5v6/0CFuvqvfCHUJR8fUrAYwQ5WCWo/gOhs6v8DF+okQp2bgr588C2CHazDIdlwsKn/J9QFoG2vcDNiWI5gB2sR7oLL1AWazdUiEep83TaACIIdrETfEFw2DXgQ6gLQtpds2nmBZhDsAHjGpn6RUBeAtgE0QbCDtTjXLlgIde62QahzGR9G8AmCHQDXEercbcPoyrVlw3ohTMsK32pvugAAwWZbqPPqe1+lgIc6mzas2xitg48Q7AC4xpa+39MM5NX3vkqEOi+FbXnhWxyKhdU4z86/bOn7CXUutG/DhgUQFSN2AJLOlr4/UOfTNWjHaKgLmzAuM3yNETsASUWoc7cd46HOho3rtTAuM3yLYAcgaQh17rZDqAPQGg7FAmgzm/p9Ql3A2jfJlr9UgDgwYgegTWzq9wl1AWsfQNwIdgASZlO/T6gLWPsAEkKwA5AQm/p9Ql3A2geQMIIdgLjZ1O8T6gLWvi04vw4+RbADEBeb+n1CXcDaB9BmBDsAMbOp3yfUucR0+wDahGAHICa25A6JUOdaDTZsXABtQrCD1fg2HzvYkDvqEepcqsGGjQugzXwV7FatWqWvf/3r6tatm1JSUrR48eJWX7Ny5UoNGjRIGRkZOuecc7RgwQLX60Ry0d8kz9GjUlVV9OeqquqeP5UNuaNeff4g1LlQQxDs2yeVlTX/2LfPdIWA63z1zROHDh3SwIEDdeONN+qb3/xmq/Nv27ZNl112mW655RYtXLhQy5cv180336zCwkKNGTPGg4oBexw9Kr34onT4sHT99VJ29snnqqqk55+XOnSQrr5aysysm25D7qjn2aBSGEOdDRu4rfbtkx59VKqpaX6e9HTp9tulzp1bfi9GMOFjvgp2Y8eO1dixY2Oef/78+erdu7ceeeQRSVL//v31zjvvaM6cOQQ7hE5NTV2o+/zzuhBXH+7qQ93nn5+cLzPTnj7f0zoIdf5VU1P3aNdOah+lazt+/OQ8QID56lBsvNasWaPRo0c3mjZmzBitWbPGUEWAOdnZdWGuU6eT4W7XrpOhrlOnk2HPlj7f61A3ZfhHhDq/a99eSktr+ogW9oAACnSwKysrU35+fqNp+fn5qqqq0pEjR6K+prq6WlVVVY0eMCNIp/7Y4tRw9+yzhLr6xlwPdF+0I4lQB8A1gQ52iZg1a5ZycnIijx49epguKdToe5IvO1u6/PLG0y6/PKShbtUqQh2i4y9L+FSgg11BQYHKy8sbTSsvL1d2draysrKivmbGjBmqrKyMPHbu3OlFqYBnqqqkJUsaT1uyRPrd7+r+b7rPD9ztTBq0RajzCdYRfCzQwa64uFjLly9vNG3ZsmUqLi5u9jUZGRnKzs5u9ID3+GPZHQ0vlOjUSZo4se7fnTul996TiorM1keoc5kNNQBwla+C3cGDB1VaWqrS0lJJdbczKS0t1Y4dOyTVjbbdcMMNkflvueUW/e1vf9P3v/99ffTRR3riiSf00ksv6Y477jBRPuJEH5Rcp4a666+XuneXzj677jYnqal1z5s6rZRQ53IdpmvwyvHj0rFjTR/Hj5uuDPCEry4TWrdunS666KLIz9OmTZMkTZw4UQsWLNCePXsiIU+Sevfurddff1133HGHHn30UXXv3l1PP/00tzpBKKWn1wU4qfGFEllZdbf2qr+PXXq697UFNtTZEKZsqcNt6el1j5oa6cSJlucBAizFcRzHdBE2q6qqUk5OjubOrVRWFodlvWDLIEcQHT1a1+9Fu1Ciqqquz6u/ObFXCHUu1yHZUYsX9u1r/QbFrd2cuF7Y1h2sVnXkiHKmTlVlZWWrp4j5asQO4cFnqTsyM5u/+bCJ00kJdS7XIdlRi1diDW2xGD6ck33hS746xw5A29nS3xPqXK5DsqMWAJ4i2MEq/IHsLlv6e0Kdy3VIdtQSBHwowWcIdrAO/ZE7bOnvCXUu1yHZUUsQsB7hQwQ7WIM/jN1jS39PqPOATbUEBR9O8BGCHaxCn5R8hDqX2zK9YuvZVEuQsE7hMwQ7IMBsCnXDhxPqXMOIkru4QhY+QrCDFWzqI4PCtlDnSUMKcaizpZ4gI9zBBwh2QADZ0NevWkWoc50NGzos6tcx4Q6WI9jBOD4nk8uGvt7TGgh1ZusIE8IdfIBgByvQNyWHDX09oc4DNmzosCLcwXIEOxjFZ2Py2NDXex3qpgz/KHyhrp5t9YQJ4Q4W47tiYRz9U9uFNdR5wrZQZ1s9YXVquGObwBKM2MEY/thNDhv6FUKdR/ilsQ+jd7AMI3YwyqY+049CFeq8PJ+uvj2bdlAbNjaiY/QOFmHEDkbY1mf6kQ19CKHOIzZsbLSuYcBjBA+GMGIH+JAN/TyhziM2bGzEruF2ahju2H7wCCN28Jxt/abf2NDPE+o8ZmNNaF3D79FjFA8eYcQOnuJzrW0IdS63Z1uAsrEmxK+5cMe2hQsIdvAcn2WJIdS5355VbKwJbXPqYdpTtzEfjkgCgh08Qz+VOEKd++1Z1anaWBOS69Rty2gekoRgB0/xWRU/G/p4Qp2HbKwJ7osW9FqbB4iCYAdPMFqXGBv6eEKdATbWBG9F2wea+yBlf0EDBDu4zub+02Y2nDfvWQ2Eujo2bHTYq7l9o7W/nNmnQoVgB0/wuRIfG/p3Qp3HGNZGolral+O9zYptvxeIG8EOrqKvip/pUOf1975KhDpr64L/xbtPufGh7cf92rbO69ixmGcl2MF1fvydNoVQ53571u2QttaFcHJjP7QtJMXCtt/HI0ekl16KaVaCHVxjOqT4jen1RagzyNa6gGRg//YUwQ6u8OMfaKbYkDkIdYaYTvMAAofvioVr6K9aZ0PmINQZwl8/AFxAsEPS0V/FxobMQagzxObaAPgawQ5JRX8VGxvWE6HOEJtrA+B7BDskHf1Vy2zo1wl1htlcGwBfI9ghaTgE2zobMgehziAulgDgMq6KRVLY3p/awIZ15HWo8yzQfdGeJHt3Qv7yAeABRuyQNLb2pzawIXMQ6gyyvT4AgUGwQ5txdKllNvTphDoL2F4fgEDgUCzahKNLLbMhc3hWg9fn0zVo0+rQxF8+ADzEiB0S5oc+1SQb1g+hzjD+8gHgMYId2sTmPtUkGzIHoc4wP9QIIHA4FIuEMBDRPBv6c8+O/hHqWuaHGgEECiN2iJuf+lWv2bBuCHUW4Lw6AIYwYoeE0Gc1ZTpzBPrGww3atH7nYzgbgEGM2CEuDEREZzpzEOos4Zc6AQQWwQ4xYyAiOtN9OaHOMn6pE0AgJSXY7d+/PxlvA4v5rW/1iun1QqizCMPZACwQd7CbPXu2Fi1aFPn5yiuv1Je+9CWdccYZ+uCDD5JaHOxCn9WY6cxBqLMIw9kALBF3sJs/f7569OghSVq2bJmWLVumN998U2PHjtVdd92V9AJhHgMRTZnOHIQ6i/ipVgCBF/dVsWVlZZFg99prr+nKK6/UJZdcol69emnYsGFJLxBmMRDRlOl+nFBnIT/VCiDQ4h6x69Spk3bu3ClJWrp0qUaPHi1JchxHJ06cSG51MMqP/avbTK8TQp1lGM4GYJm4R+y++c1v6tprr1WfPn302WefaezYsZKkjRs36pxzzkl6gTCLPusk0304oc4yDGcDsFDcwW7OnDnq1auXdu7cqQcffFAdO3aUJO3Zs0f/9m//lvQCYYbpEGMb0+uDUGcZv9ULIDTiDnZpaWn693//9ybT77jjjqQUBPMYiDjJhv6bUGcpv9ULIBRiCnZLlizR2LFjlZaWpiVLlrQ47+WXX56UwmCGX/tYN9iwLgh1FuIvHwAWiynYjR8/XmVlZcrLy9P48eObnS8lJYULKHzMj32sW2xYF4Q6C/mxZgChElOwq62tjfp/BA/9lR19t6fn9BHq4uPHmgGERlK/K/bw4cPJfDt4yPTFAbawIW8Q6izFIVgAPhB3sBs1apR2797dZPratWtVVFSUjJpaNG/ePPXq1UuZmZkaNmyY3nvvvWbnXbBggVJSUho9MjMzXa/Rb+iv6pjOG6tWeR/qpgz/iFAXC7/WDSB04g52mZmZuuCCCyLfF1tbW6sf/ehH+ud//meNGzcu6QU2tGjRIk2bNk333nuvNmzYoIEDB2rMmDGqqKho9jXZ2dnas2dP5LF9+3ZXa/Qb+qs6pteD5+1/EeqM8OvO5te6AYRK3Lc7ef311zVv3jzdeOONevXVV/Xpp59q+/bteu2113TJJZe4UWPEz3/+c02ePFmTJk2SVPe9ta+//rqeeeYZTZ8+PeprUlJSVFBQ4GpdfmU6zNjC9HoITajz6/F+v9YNIJTiDnaSdOutt2rXrl2aPXu22rdvr5UrV6qkpCTZtTVSU1Oj9evXa8aMGZFpqampGj16tNasWdPs6w4ePKiePXuqtrZWgwYN0k9/+lOdd955rtbqB6bDjC1Mr4fAX/nasG0/7mycpwDAZ+I+FPv555/rW9/6ln7xi1/oySef1JVXXqlLLrlETzzxhBv1RfzjH//QiRMnlJ+f32h6fn6+ysrKor6mb9++euaZZ/Tqq6/q+eefV21trUpKSrRr165m26murlZVVVWjR1D5sZ9NJkKdR/wa6ur5uXYAoRN3sDv//PNVXl6ujRs3avLkyXr++ef1y1/+Uvfcc48uu+wyN2pMWHFxsW644QYVFRVpxIgRevnll9W1a1c9+eSTzb5m1qxZysnJiTx69OjhYcXe8Hs/mwyEOo/4eWfzc+0AQivuYHfLLbdo1apV6t27d2TaVVddpQ8++EA1NTVJLa6hLl26qF27diovL280vby8POZz6NLS0nThhRfqk08+aXaeGTNmqLKyMvLYuXNnm+q2DUeWCHWe8XMw4hcFgE/FHezuuecepaY2fVn37t21bNmypBQVTXp6ugYPHqzly5dHptXW1mr58uUqLi6O6T1OnDihTZs2qbCwsNl5MjIylJ2d3egRFKYDjQ1MrwNCnY/4vX4AoZTQxRNS3c2Id+zY0WSU7oILLmhzUc2ZNm2aJk6cqCFDhmjo0KGaO3euDh06FLlK9oYbbtAZZ5yhWbNmSZLuv/9+/dM//ZPOOecc7d+/Xw899JC2b9+um2++2bUabWU60NjA9DoIVajzsyCEUgChFXew27t3ryZNmqQ333wz6vNuflfsVVddpb1792rmzJkqKytTUVGRli5dGrmgYseOHY1GEz///HNNnjxZZWVl6tSpkwYPHqzVq1fry1/+sms12sh0oLGB6XUQulDn153N76EUQOilOI7jxPOC6667Ttu3b9fcuXM1cuRIvfLKKyovL9ePf/xjPfLII9ZdQNFWVVVVysnJ0dy5lcrK8udh2bAPQJjOGoQ6Hwn7LwsAK1UdOaKcqVNVWVnZ6ilicY/YrVixQq+++qqGDBmi1NRU9ezZUxdffLGys7M1a9aswAU7vwt7P2V6+Ql1PsJoHYAAiDvYHTp0SHl5eZKkTp06ae/evTr33HM1YMAAbdiwIekFInFh76dsCHVefpuERKhLWBCWAQCUQLDr27evtmzZol69emngwIF68skn1atXL82fP7/Fq03hrTD3UzYsO6HOh4KwDABCL+5gd/vtt2vPnj2SpHvvvVeXXnqpFi5cqPT0dC1YsCDZ9SEBQepr42V62U1876tEqGuTsA9tAwiUuIPd9ddfH/n/4MGDtX37dn300Uc688wz1aVLl6QWh/gFpa9NhOllJ9T5WFCWA0DoxX2D4obeffddtWvXToMGDSLUWSBofW08TC87oc6nTJ+ICQBJ1qZgN3bsWO3evTtZtaANgtTXxsv0shPqfIpDsAACqE3BLs5b4MFlQehr42U6ZxDqfC5IywIAamOwgx3CejTJdM4g1PkYo3UAAiruYDdx4kSt+uJD8cknn4x8nRfMCGv/ZDpnEOoCIGjLAwBKINhVVlZq9OjR6tOnj7Zt26b9+/e7UBZiEdT+tjWml9tEqJsy/CNCXbKEdYgbQCjEHewWL16s3bt367vf/a5eeukl9erVS2PHjtV//dd/6dixY27UiCiC2N/GwvRymwp1Rphe2W4I6xA3gNBI6By7rl27atq0afrggw+0du1anXPOOZowYYK6deumO+64Qx9//HGy60QDQexvY2F6uT3/3ldCnTuCuEwA8IU2XTyxZ88eLVu2TMuWLVO7du00btw4bdq0SV/+8pc1Z86cZNWIBoLc37bE9HJ7Hupk6Hy6Bu0HbidjtA5ACMT9zRPHjh3TkiVL9Ktf/Uq///3vdcEFF2jq1Km69tprlZ2dLUl65ZVXdOONN+qOO+5IesFhFtT+tjWmT4kKzfe+Nmg/sDtZUJcLAL4Qd7ArLCxUbW2trrnmGr333nsqKipqMs9FF12k3NzcJJSHekHvb6MxvcyhuvK1QfuB3MkYrQMQEnEHuzlz5uiKK65QZmZms/Pk5uZq27ZtbSoMJwW5v22O6WUm1AVQkJcNAL4Qd7CbMGGCG3WgGWHob09lepkJdQFj+lg+AHiIb57wgTD1SaYzBqEOAOBnBDuLhW2gwXTGINQFUNh+iQCEHsHOUmHrj0xnDEJdAHHBBIAQIthZKGz9kemMEbpQVy/Ioa5eGJYRABog2FnGdMjxmunlDWWoC8NwcNj+OgKALxDsLGI65HjN9PIS6gIuLMsJAA0Q7CxhOuR4zfTyEuoCjNE6ACEW933skHymQ47XTC+v5/mGUOe9MC0rADRAsDPMdMjxmsl8YWRdE+q8xWgdgJAj2BkUplBnellNhTrjV76GKdTVC9vyAkADBDtDTAcdL5le1lCeT9egDgBAeHDxhAGmg46XTC9r6ENdGHayemEcnQSAUxDsPBam/tb0shLqQrCTAQAaIdh5KEz9rellJdSFYCdriMPOACCJYOeZMPW3ppeVUBeCnSyasC43ADRAsPNAmPpb08tKqAvBTnYqRusAIIJg57Iw9beml5VQF4KdrDlhXnYAaIDbnbgoTP2t6WUN5bdJNKgjFDsZAKBVBDuXhKm/5dskDAnTTtYcbnECAI0Q7FwQlv7W9HIS6hT8nQwAEBfOsUuysPS3ppeTUKfg72St4aIJAGiCYJdEYelvTS8noU7B38lixXoAgEYIdkkSlv7W9HIS6hT8nQwAkDDOsUuCsPS3ppfTVKgzHui+qENS8HeyWHEYFgCiYsSujcLS35peTkKdgr+TxYv1AQBNMGLXBmHpb00vZ2hvPCyZX/kAAF8h2CUoLP2t6eUM7Y2HJfMr31YchgWAZhHsEhCW/pYbDxsUlp0sUawXAIiKYBenMPS3ppeRUBeCnQwA4AounohDGPpb08tIqAvBTtYWHIYFgBYR7GK0enXdv0Hub01nCkIdoS4mrB8AaBbBLg5B7k9MZwpCHaEOANB2BLsYlZSYrsA9pjMFoY5QBwBIDoJdyJnOFIQ6Qh0AIHkIdiFmOlMQ6gh1cTF5/x0A8AludxJSJjOFsbYJdQCAgCPYhYzpPGEy1FkR6CTzGwEAEFgEuxAxnSdCf+hVMr8RAACBxjl2IWE6TxDqZH4jAAACjxG7EDCdJwh1Mr8R6u3bJ9XUNP98errUubN39QBJdPBoex2uaa+87KNNnquoylSH9OPqmHncQGWAd3wX7ObNm6eHHnpIZWVlGjhwoB5//HENHTq02fl/+9vf6p577tGnn36qPn36aPbs2Ro3bpyHFZtlOk8Q6mR+I9Tbt0969NHWg93tt9sX7vgqMbTi4NH2+r8vfkX7DmfoqevfVn72kchz5VVZmvL8P6tzh2o9fvW7hDsEmq8OxS5atEjTpk3Tvffeqw0bNmjgwIEaM2aMKioqos6/evVqXXPNNbrpppu0ceNGjR8/XuPHj9df/vIXjys3w3SeINTJ/EZoqKam7tGunZSR0fTRrt3JeWxkwzqEtQ7XtNe+wxna/flpmvL8P6u8KkvSyVC3+/PTtO9whg7X+G48A4iLr4Ldz3/+c02ePFmTJk3Sl7/8Zc2fP18dOnTQM888E3X+Rx99VJdeeqnuuusu9e/fXw888IAGDRqk//zP//S4cu+ZzhOEOpnfCM1p315KS2v6aE+HB//Kyz6qp65/W2d0OhQJd3/e1TkS6s7odEhPXf921MO0QJD4JtjV1NRo/fr1Gj16dGRaamqqRo8erTVr1kR9zZo1axrNL0ljxoxpdn5Jqq6uVlVVVaOH35i+R139fWQJdbIv1AEBlp99pFG4u/HZEY1CXcPDs0BQ+SbY/eMf/9CJEyeUn5/faHp+fr7KysqivqasrCyu+SVp1qxZysnJiTx69OjR9uI9YixUNWhfCvmNhyVCHWBQfvYRPXD5ukbTHrh8HaEOoeGbYOeVGTNmqLKyMvLYuXOn6ZJiYjpLEOq+YHpDACFXXpWle5YMaTTtniVDIufcAUHnm2DXpUsXtWvXTuXl5Y2ml5eXq6CgIOprCgoK4ppfkjIyMpSdnd3oYTvTWYJQ9wXTGwIIuYYXSpzR6ZCemfjHRufcEe4QBr4Jdunp6Ro8eLCWL18emVZbW6vly5eruLg46muKi4sbzS9Jy5Yta3Z+PzKdJUx/RRihLgHHj0vHjjV9HOcWEPCviqrMJhdKXNB9X5MLKiqqMk2XCrjKV5fBTZs2TRMnTtSQIUM0dOhQzZ07V4cOHdKkSZMkSTfccIPOOOMMzZo1S5J0++23a8SIEXrkkUd02WWX6cUXX9S6dev01FNPmVyMpDGdJbjy9QumN0Ss0tPrHjU10okTLc8D+EyH9OPq3KFakhpdKFF/QUX9few6pPMHDILNV8Huqquu0t69ezVz5kyVlZWpqKhIS5cujVwgsWPHDqWmnhyELCkp0QsvvKC7775bP/zhD9WnTx8tXrxY559/vqlFSBrTWYJQdwrbQ51Ud9Ph22/37zdP1F8ZBETRMfO4Hr/63ajfPJGffUT/7/pVfPMEQiHFcRzHdBE2q6qqUk5OjubOrVRWlh3n2xHqLELY8A7rGkBIVR05opypU1VZWdnquf++GrELu1AGugYNE+oAAGiZby6eCDtCHaEOAIDWEOx8gFBHqAMAIBYEO8sR6gh1aKB+hwQAREWwsxihjlCHBlj3ANAqgp2lCHWEOgAA4sVVsRYKZaizNdBJhDrbsD0AoFkEO4uEMtA1aJhQh1YNH855dgDQAg7FWoJQR6hDHAh3ABAVwc4ChDpCHeLAdgGAZhHsDCPUEeqQIEbtAKAJgp1BhDpCHRLENgKAqAh2hhDqCHVIAkbtAKARgp0BhDpCHZKgfnsR7gAggtudeCi0ga5B44Q6JFX97U/YhgAgiWDnmdCGOpsDnUQgCALCHQBEcCjWA4Q6C0MdQSBYOCwLAJIIdq4j1Fka6iRCXdAQ7gCAYOcm0/mBUBeF6Y0CdxHuAIQcwc4lpvMDoS4K0xsF3iDcAQgxLp5IMtPZgStfm2F6w8Bbp4Y7tjuAkGDELolM9yGEumaY3jAwp2HAYwQPQAgQ7JLEdHYg1DXD9IaBecOHE/AAhAaHYpPAdHYwHeqsDHSS+Q0Du0QLd+wbAAKGYNdGpvsHLpJohukNA3sR8AAEGIdi28B0n0Coa4bpDQN/4BAtgABixC4BNuQGQl0zbNg48JeG+0rDcMc+BMCHCHZxMp0bTJ9PJxHqEGDNhbxTnwOAtornKMGxYzHPSrCLg+ncQKhrgemNg+A5NeQxmgeEj5unaMTzOXLkiPTSSzHNSrCL0erVUloaoc5KhDq47dR9K9qHPfsfYI4tAcwCBLs4EOosRKiDCdGCHmEPaBnhyxMEuxiVlJhpl4skWkCogy2a2wdb6sjYb2EjwpfvEewsRqhrAaEOftBS4GutA2XfRkNe3Y6H/c73CHYW4tBrKwh18LtY9t1EO3J+L9xn4p6HbFfEiGBnGUJdKwh1CItE9nFutOwNPn9gMYKdRQh1rSDUAS3jdwMIPb5SzBKEulYQ6gAAaBXBzgKEulYQ6gAAiAmHYg0zHeqsDnQSoQ4AgDgQ7AwxHegky0fpJEIdAABx4lCsAYS6GBDqAACIG8HOY4S6GBDqAABICMHOQ4S6GBDqAABIGMHOI4S6GBDqAABoEy6ecJnxrEKoAwAgNAh2LjKeVfxwOxPJghUFAEAwEOxcwqHXGBHqAABIGs6xcwGhLkaEOgAAkopgl2SEuhgR6gAASDqCXRIR6mJEqAMAwBWcY5cExnOK30IdgQ4AAFcwYtdGhLo4EOoAAHAVI3ZtwKHXOBDqAABwHcEuQYS6GBkf0gQAIDw4FJsAQl2MCHUAAHiKEbs4GM8phDoAANACRuxitHp13b+EuhgQ6gAAMMI3wW7fvn267rrrlJ2drdzcXN100006ePBgi68ZOXKkUlJSGj1uueWWhGsg1MWAUAcAgDG+ORR73XXXac+ePVq2bJmOHTumSZMmacqUKXrhhRdafN3kyZN1//33R37u0KFDQu2XlCT0srZbtcofgU4i1AEAYJgvgt3mzZu1dOlSvf/++xoyZIgk6fHHH9e4ceP08MMPq1u3bs2+tkOHDiooKPCq1OTx0yidRKgDAMACvjgUu2bNGuXm5kZCnSSNHj1aqampWrt2bYuvXbhwobp06aLzzz9fM2bM0OHDh1ucv7q6WlVVVY0eniPUAQCABPhixK6srEx5eXmNprVv316dO3dWWVlZs6+79tpr1bNnT3Xr1k1//vOf9YMf/EBbtmzRyy+/3OxrZs2apfvuuy9ptceNUAcAABJkNNhNnz5ds2fPbnGezZs3J/z+U6ZMifx/wIABKiws1KhRo7R161adffbZUV8zY8YMTZs2LfJzVVWVevTokXANcSHUAQCANjAa7O688059+9vfbnGes846SwUFBaqoqGg0/fjx49q3b19c588NGzZMkvTJJ580G+wyMjKUkZER83smDaEOAAC0kdFg17VrV3Xt2rXV+YqLi7V//36tX79egwcPliStWLFCtbW1kbAWi9LSUklSYWFhQvW6xk9XvkqEOgAALOWLiyf69++vSy+9VJMnT9Z7772nd999V7fddpuuvvrqyBWxu3fvVr9+/fTee+9JkrZu3aoHHnhA69ev16effqolS5bohhtu0PDhw3XBBReYXJyTVq0i1AEAgKTxRbCT6q5u7devn0aNGqVx48bpq1/9qp566qnI88eOHdOWLVsiV72mp6frrbfe0iWXXKJ+/frpzjvv1Le+9S39z//8j6lFaMxvh14lQh0AAJbzxVWxktS5c+cWb0bcq1cvOY4T+blHjx764x//6EVp8SPUAQAAF/gm2AWGX0MdgQ4AAOv55lBsIBDqAACAixix8woXSQAAAJcR7Nzm11E6iVAHAIDPcCjWTYQ6AADgIYKdWwh1AADAYwQ7NxDqAACAAQS7ZCPUAQAAQ7h4Iln8GOgkQh0AAAHCiF0yEOoAAIAFCHZtRagDAACWINi1BaEOAABYhGCXKEIdAACwDBdPJMLPoY5ABwBAYBHs4uHXQCcR6gAACAGCXaxWvyulnea/UMehVwAAQoNz7OJAqAMAADYj2MVoUsn/mi4hPoQ6AABCh2AXRIQ6AABCiWAXNIQ6AABCi2AXJIQ6AABCjWAXFIQ6AABCj2AXBIQ6AAAggp3/EeoAAMAXuEGxn/FtEgAAoAGCnR8xSgcAAKLgUKzfEOoAAEAzCHZ+QqgDAAAtINj5BaEOAAC0gmDnB4Q6AAAQA4Kd7Qh1AAAgRgQ7mxHqAABAHAh2tiLUAQCAOBHsbESoAwAACeAGxbbh2yQAAECCCHa2YJQOAAC0EYdibUCoAwAASUCwM41QBwAAkoRgZxKhDgAAJBHBzhRCHQAASDKCnQmEOgAA4AKCndcIdQAAwCUEOy8R6gAAgIu4j50XCHQAAMADjNi5jVAHAAA8QrBzE6EOAAB4iGDnFkIdAADwGMHODYQ6AABgAMEu2Qh1AADAEIJdMhHqAACAQQS7ZCHUAQAAw7iPXVsR6AAAgCUYsWsLQh0AALAIwS5RhDoAAGAZgl0iCHUAAMBCBLt4EeoAAIClCHbxINQBAACL+SbY/eQnP1FJSYk6dOig3NzcmF7jOI5mzpypwsJCZWVlafTo0fr4448TK2D16rp/CXUAAMBSvgl2NTU1uuKKK/Td73435tc8+OCDeuyxxzR//nytXbtWp512msaMGaOjR4/GX0BJCaEOAABYzTf3sbvvvvskSQsWLIhpfsdxNHfuXN199936xje+IUn69a9/rfz8fC1evFhXX321W6UCAAAY4ZsRu3ht27ZNZWVlGj16dGRaTk6Ohg0bpjVr1hisDAAAwB2+GbGLV1lZmSQpPz+/0fT8/PzIc9FUV1eruro68nNlZaUkqSqRw7cAAABtVJ9BHMdpdV6jwW769OmaPXt2i/Ns3rxZ/fr186giadasWZHDvg31mD7dsxoAAABOdeDAAeXk5LQ4j9Fgd+edd+rb3/52i/OcddZZCb13QUGBJKm8vFyFhYWR6eXl5SoqKmr2dTNmzNC0adMiP+/fv189e/bUjh07Wl2ZaLuqqir16NFDO3fuVHZ2tulyAo117S3Wt7dY395ifbvLcRwdOHBA3bp1a3Veo8Gua9eu6tq1qyvv3bt3bxUUFGj58uWRIFdVVaW1a9e2eGVtRkaGMjIymkzPyclhZ/VQdnY269sjrGtvsb69xfr2FuvbPbEOLvnm4okdO3aotLRUO3bs0IkTJ1RaWqrS0lIdPHgwMk+/fv30yiuvSJJSUlI0depU/fjHP9aSJUu0adMm3XDDDerWrZvGjx9vaCkAAADc45uLJ2bOnKlnn3028vOFF14oSfrDH/6gkSNHSpK2bNkSudhBkr7//e/r0KFDmjJlivbv36+vfvWrWrp0qTIzMz2tHQAAwAu+CXYLFixo9R52p14tkpKSovvvv1/3339/wu1mZGTo3nvvjXp4FsnH+vYO69pbrG9vsb69xfq2R4oTy7WzAAAAsJ5vzrEDAABAywh2AAAAAUGwAwAACAiCXRQ/+clPVFJSog4dOig3Nzem1ziOo5kzZ6qwsFBZWVkaPXq0Pv74Y3cLDYB9+/bpuuuuU3Z2tnJzc3XTTTc1uoVNNCNHjlRKSkqjxy233OJRxf4yb9489erVS5mZmRo2bJjee++9Fuf/7W9/q379+ikzM1MDBgzQG2+84VGlwRDP+l6wYEGT/Zgr9mO3atUqff3rX1e3bt2UkpKixYsXt/qalStXatCgQcrIyNA555zT6gV5qBPvul65cmWTfTslJaXFr/NE8hDsoqipqdEVV1zR4o2MT/Xggw/qscce0/z587V27VqddtppGjNmjI7yHbMtuu666/Thhx9q2bJleu2117Rq1SpNmTKl1ddNnjxZe/bsiTwefPBBD6r1l0WLFmnatGm69957tWHDBg0cOFBjxoxRRUVF1PlXr16ta665RjfddJM2btyo8ePHa/z48frLX/7iceX+FO/6lupu5tpwP96+fbuHFfvboUOHNHDgQM2bNy+m+bdt26bLLrtMF110kUpLSzV16lTdfPPN+t3vfudypf4X77qut2XLlkb7d15enksVohEHzfrVr37l5OTktDpfbW2tU1BQ4Dz00EORafv373cyMjKc3/zmNy5W6G9//etfHUnO+++/H5n25ptvOikpKc7u3bubfd2IESOc22+/3YMK/W3o0KHOrbfeGvn5xIkTTrdu3ZxZs2ZFnf/KK690LrvsskbThg0b5nznO99xtc6giHd9x/r5gtZJcl555ZUW5/n+97/vnHfeeY2mXXXVVc6YMWNcrCx4YlnXf/jDHxxJzueff+5JTWiMEbsk2LZtm8rKyjR69OjItJycHA0bNkxr1qwxWJnd1qxZo9zcXA0ZMiQybfTo0UpNTdXatWtbfO3ChQvVpUsXnX/++ZoxY4YOHz7sdrm+UlNTo/Xr1zfaJ1NTUzV69Ohm98k1a9Y0ml+SxowZwz4cg0TWtyQdPHhQPXv2VI8ePfSNb3xDH374oRflhhL7t/eKiopUWFioiy++WO+++67pckLDNzcotln9eQP5+fmNpufn53NOQQvKysqaDM23b99enTt3bnG9XXvtterZs6e6deumP//5z/rBD36gLVu26OWXX3a7ZN/4xz/+oRMnTkTdJz/66KOorykrK2MfTlAi67tv37565plndMEFF6iyslIPP/ywSkpK9OGHH6p79+5elB0qze3fVVVVOnLkiLKysgxVFjyFhYWaP3++hgwZourqaj399NMaOXKk1q5dq0GDBpkuL/BCE+ymT5+u2bNntzjP5s2b1a9fP48qCq5Y13WiGp6DN2DAABUWFmrUqFHaunWrzj777ITfF/BScXGxiouLIz+XlJSof//+evLJJ/XAAw8YrAxom759+6pv376Rn0tKSrR161bNmTNHzz33nMHKwiE0we7OO+/Ut7/97RbnOeussxJ674KCAklSeXm5CgsLI9PLy8tVVFSU0Hv6WazruqCgoMmJ5cePH9e+ffsi6zQWw4YNkyR98sknBLsvdOnSRe3atVN5eXmj6eXl5c2u24KCgrjmx0mJrO9TpaWl6cILL9Qnn3ziRomh19z+nZ2dzWidB4YOHap33nnHdBmhEJpg17VrV3Xt2tWV9+7du7cKCgq0fPnySJCrqqrS2rVr47qyNihiXdfFxcXav3+/1q9fr8GDB0uSVqxYodra2khYi0VpaakkNQrVYZeenq7Bgwdr+fLlGj9+vCSptrZWy5cv12233Rb1NcXFxVq+fLmmTp0ambZs2bJGo0qILpH1faoTJ05o06ZNGjdunIuVhldxcXGT2/ewf3untLSUz2ivmL56w0bbt293Nm7c6Nx3331Ox44dnY0bNzobN250Dhw4EJmnb9++zssvvxz5+Wc/+5mTm5vrvPrqq86f//xn5xvf+IbTu3dv58iRIyYWwTcuvfRS58ILL3TWrl3rvPPOO06fPn2ca665JvL8rl27nL59+zpr1651HMdxPvnkE+f+++931q1b52zbts159dVXnbPOOssZPny4qUWw1osvvuhkZGQ4CxYscP761786U6ZMcXJzc52ysjLHcRxnwoQJzvTp0yPzv/vuu0779u2dhx9+2Nm8ebNz7733Omlpac6mTZtMLYKvxLu+77vvPud3v/uds3XrVmf9+vXO1Vdf7WRmZjoffvihqUXwlQMHDkQ+myU5P//5z52NGzc627dvdxzHcaZPn+5MmDAhMv/f/vY3p0OHDs5dd93lbN682Zk3b57Trl07Z+nSpaYWwTfiXddz5sxxFi9e7Hz88cfOpk2bnNtvv91JTU113nrrLVOLECoEuygmTpzoSGry+MMf/hCZR5Lzq1/9KvJzbW2tc8899zj5+flORkaGM2rUKGfLli3eF+8zn332mXPNNdc4HTt2dLKzs51JkyY1CtDbtm1rtO537NjhDB8+3OncubOTkZHhnHPOOc5dd93lVFZWGloCuz3++OPOmWee6aSnpztDhw51/vSnP0WeGzFihDNx4sRG87/00kvOueee66SnpzvnnXee8/rrr3tcsb/Fs76nTp0amTc/P98ZN26cs2HDBgNV+1P9LTVOfdSv44kTJzojRoxo8pqioiInPT3dOeussxp9hqN58a7r2bNnO2effbaTmZnpdO7c2Rk5cqSzYsUKM8WHUIrjOI7Hg4QAAABwAfexAwAACAiCHQAAQEAQ7AAAAAKCYAcAABAQBDsAAICAINgBAAAEBMEOAAAgIAh2AAAAAUGwAwBLjBw5stF39QJAvPjmCQCwxL59+5SWlqbTTz/ddCkAfIpgBwAAEBAcigWAU+zdu1cFBQX66U9/Gpm2evVqpaena/ny5VFf8/777+viiy9Wly5dlJOToxEjRmjDhg2R51euXKn09HS9/fbbkWkPPvig8vLyVF5eLqnpodgnnnhCffr0UWZmpvLz8/Wv//qvSV5SAEFDsAOAU3Tt2lXPPPOMfvSjH2ndunU6cOCAJkyYoNtuu02jRo2K+poDBw5o4sSJeuedd/SnP/1Jffr00bhx43TgwAFJJ0PbhAkTVFlZqY0bN+qee+7R008/rfz8/Cbvt27dOn3ve9/T/fffry1btmjp0qUaPny4q8sNwP84FAsAzbj11lv11ltvaciQIdq0aZPef/99ZWRkxPTa2tpa5ebm6oUXXtC//Mu/SJJqamo0bNgwnXvuufrLX/6ir3zlK3rqqacirxk5cqSKioo0d+5cvfzyy5o0aZJ27drFOXcAYsaIHQA04+GHH9bx48f129/+VgsXLlRGRoZ27Nihjh07Rh71h2vLy8s1efJk9enTRzk5OcrOztbBgwe1Y8eOyPulp6dr4cKF+u///m8dPXpUc+bMabbtiy++WD179tRZZ52lCRMmaOHChTp8+LDrywzA39qbLgAAbLV161b9/e9/V21trT799FMNGDBA3bp1U2lpaWSezp07S5ImTpyozz77TI8++qh69uypjIwMFRcXq6amptF7rl69WlLdFbD79u3TaaedFrXt008/XRs2bNDKlSv1+9//XjNnztSPfvQjvf/++8rNzXVleQH4H4diASCKmpoaDR06VEVFRerbt6/mzp2rTZs2KS8vL+r8p59+up544glNmDBBkrRz506deeaZmjNnTuSCiK1bt6qoqEiPPfaYFi1apJqaGr311ltKTa07eNLwUOypDh06pNzcXC1atEjf/OY3XVlmAP7HiB0ARPEf//Efqqys1GOPPaaOHTvqjTfe0I033qjXXnst6vx9+vTRc889pyFDhqiqqkp33XWXsrKyIs+fOHFC119/vcaMGaNJkybp0ksv1YABA/TII4/orrvuavJ+r732mv72t79p+PDh6tSpk9544w3V1taqb9++ri0zAP/jHDsAOMXKlSs1d+5cPffcc8rOzlZqaqqee+45vf322/rFL34R9TW//OUv9fnnn2vQoEGaMGGCvve97zUa3fvJT36i7du368knn5QkFRYW6qmnntLdd9+tDz74oMn75ebm6uWXX9bXvvY19e/fX/Pnz9dvfvMbnXfeee4sNIBA4FAsAABAQDBiBwAAEBAEOwAAgIAg2AEAAAQEwQ4AACAgCHYAAAABQbADAAAICIIdAABAQBDsAAAAAoJgBwAAEBAEOwAAgIAg2AEAAAQEwQ4AACAg/j+mUkLj8jGA0QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercises\n",
        "\n",
        "1)Try using the MLP classifier for different logic gates other than XOR like AND, OR, NOR etc.\n",
        "\n",
        "2)Try to change 0/1 logic to -1/+1 logic. What happens with an SLP in this case? What about an MLP?\n",
        "\n",
        "3)Try removing the activation function from the MLP and rerun the code. What happens in this case?\n",
        "\n",
        "Can you tell why particular activation function can be used in the model architecture?"
      ],
      "metadata": {
        "id": "nalrbjA7Gu1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1) MLP classifier for AND,OR,NOR gate"
      ],
      "metadata": {
        "id": "bbjXlo9jHlPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Training data for AND gate\n",
        "X = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
        "y_and = [0, 0, 0, 1]\n",
        "\n",
        "# Create and train MLP classifier\n",
        "clf_and = MLPClassifier(hidden_layer_sizes=(), activation='logistic', solver='lbfgs', max_iter=1000)\n",
        "clf_and.fit(X, y_and)\n",
        "\n",
        "# Test the AND gate\n",
        "print(\"AND Gate:\")\n",
        "print(\"(0, 0) ->\", clf_and.predict([[0, 0]]))  # Expect 0\n",
        "print(\"(0, 1) ->\", clf_and.predict([[0, 1]]))  # Expect 0\n",
        "print(\"(1, 0) ->\", clf_and.predict([[1, 0]]))  # Expect 0\n",
        "print(\"(1, 1) ->\", clf_and.predict([[1, 1]]))  # Expect 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLig0ANmHzO3",
        "outputId": "ccf7f371-01b3-4d62-e6ec-4950f1f4abaf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND Gate:\n",
            "(0, 0) -> [0]\n",
            "(0, 1) -> [0]\n",
            "(1, 0) -> [0]\n",
            "(1, 1) -> [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data for OR gate\n",
        "y_or = [0, 1, 1, 1]\n",
        "\n",
        "# Create and train MLP classifier\n",
        "clf_or = MLPClassifier(hidden_layer_sizes=(), activation='logistic', solver='lbfgs', max_iter=1000)\n",
        "clf_or.fit(X, y_or)\n",
        "\n",
        "# Test the OR gate\n",
        "print(\"\\nOR Gate:\")\n",
        "print(\"(0, 0) ->\", clf_or.predict([[0, 0]]))  # Expect 0\n",
        "print(\"(0, 1) ->\", clf_or.predict([[0, 1]]))  # Expect 1\n",
        "print(\"(1, 0) ->\", clf_or.predict([[1, 0]]))  # Expect 1\n",
        "print(\"(1, 1) ->\", clf_or.predict([[1, 1]]))  # Expect 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5cjg9ysICAh",
        "outputId": "041db4b2-1980-4670-f7f7-d002dfc9e59e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "OR Gate:\n",
            "(0, 0) -> [0]\n",
            "(0, 1) -> [1]\n",
            "(1, 0) -> [1]\n",
            "(1, 1) -> [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data for NOR gate\n",
        "y_nor = [1, 0, 0, 0]\n",
        "\n",
        "# Create and train MLP classifier\n",
        "clf_nor = MLPClassifier(hidden_layer_sizes=(), activation='logistic', solver='lbfgs', max_iter=1000)\n",
        "clf_nor.fit(X, y_nor)\n",
        "\n",
        "# Test the NOR gate\n",
        "print(\"\\nNOR Gate:\")\n",
        "print(\"(0, 0) ->\", clf_nor.predict([[0, 0]]))  # Expect 1\n",
        "print(\"(0, 1) ->\", clf_nor.predict([[0, 1]]))  # Expect 0\n",
        "print(\"(1, 0) ->\", clf_nor.predict([[1, 0]]))  # Expect 0\n",
        "print(\"(1, 1) ->\", clf_nor.predict([[1, 1]]))  # Expect 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gbts5-sGIRW8",
        "outputId": "519c2258-7735-422b-ffab-4b9620e9cf90"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NOR Gate:\n",
            "(0, 0) -> [1]\n",
            "(0, 1) -> [0]\n",
            "(1, 0) -> [0]\n",
            "(1, 1) -> [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2)\n",
        "# Modified training data for AND gate with -1/+1 logic\n",
        "# Training data for AND gate\n",
        "X_and_modified = [[-1, -1], [-1, 1], [1, -1], [1, 1]]\n",
        "y_and_modified = [-1, -1, -1, +1]\n",
        "\n",
        "# Create and train SLP classifier\n",
        "clf_and_slp = MLPClassifier(hidden_layer_sizes=(), activation='identity', solver='lbfgs', max_iter=1000)\n",
        "clf_and_slp.fit(X, y_and_modified)\n",
        "\n",
        "# Create and train MLP classifier\n",
        "clf_and_mlp = MLPClassifier(hidden_layer_sizes=(), activation='logistic', solver='lbfgs', max_iter=1000)\n",
        "clf_and_mlp.fit(X, y_and_modified)\n",
        "\n",
        "# Test the AND gate with SLP\n",
        "print(\"AND Gate with SLP:\")\n",
        "print(\"(+1, +1) ->\", clf_and_slp.predict([[+1, +1]]))  # Expect +1\n",
        "print(\"(+1, -1) ->\", clf_and_slp.predict([[+1, -1]]))  # Expect -1\n",
        "print(\"(-1, +1) ->\", clf_and_slp.predict([[-1, +1]]))  # Expect -1\n",
        "print(\"(-1, -1) ->\", clf_and_slp.predict([[-1, -1]]))  # Expect -1\n",
        "\n",
        "# Test the AND gate with MLP\n",
        "print(\"\\nAND Gate with MLP:\")\n",
        "print(\"(+1, +1) ->\", clf_and_mlp.predict([[+1, +1]]))  # Expect +1\n",
        "print(\"(+1, -1) ->\", clf_and_mlp.predict([[+1, -1]]))  # Expect -1\n",
        "print(\"(-1, +1) ->\", clf_and_mlp.predict([[-1, +1]]))  # Expect -1\n",
        "print(\"(-1, -1) ->\", clf_and_mlp.predict([[-1, -1]]))  # Expect -1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwdk3R36Iszf",
        "outputId": "f4d471d8-afa0-4153-f924-2a84a2e1f9f7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND Gate with SLP:\n",
            "(+1, +1) -> [1]\n",
            "(+1, -1) -> [-1]\n",
            "(-1, +1) -> [-1]\n",
            "(-1, -1) -> [-1]\n",
            "\n",
            "AND Gate with MLP:\n",
            "(+1, +1) -> [1]\n",
            "(+1, -1) -> [-1]\n",
            "(-1, +1) -> [-1]\n",
            "(-1, -1) -> [-1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3)\n",
        "# Create and train MLP classifier without activation function\n",
        "clf_and_mlp_no_activation = MLPClassifier(hidden_layer_sizes=(), activation='identity', solver='lbfgs', max_iter=1000)\n",
        "clf_and_mlp_no_activation.fit(X, y_and_modified)\n",
        "\n",
        "# Test the AND gate with MLP without activation function\n",
        "print(\"\\nAND Gate with MLP (No Activation Function):\")\n",
        "print(\"(+1, +1) ->\", clf_and_mlp_no_activation.predict([[+1, +1]]))  # Expect +1\n",
        "print(\"(+1, -1) ->\", clf_and_mlp_no_activation.predict([[+1, -1]]))  # Expect -1\n",
        "print(\"(-1, +1) ->\", clf_and_mlp_no_activation.predict([[-1, +1]]))  # Expect -1\n",
        "print(\"(-1, -1) ->\", clf_and_mlp_no_activation.predict([[-1, -1]]))  # Expect -1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEC_gEfqJvud",
        "outputId": "516baad2-f609-4572-ec9d-fefa22920d33"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AND Gate with MLP (No Activation Function):\n",
            "(+1, +1) -> [1]\n",
            "(+1, -1) -> [-1]\n",
            "(-1, +1) -> [-1]\n",
            "(-1, -1) -> [-1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Q3)\n",
        "\n",
        "When removing the activation function from the MLP, it essentially becomes a linear classifier, as it applies only linear transformations to the input data without any non-linear activation. In this case, the MLP behaves very similarly to a Single-Layer Perceptron (SLP), as it can only learn linearly separable patterns.\n",
        "\n",
        "For the AND gate, which is a linearly separable problem, both the SLP and the MLP without activation function can learn the correct weights to classify the inputs. However, for more complex problems that are not linearly separable, the absence of an activation function severely limits the expressive power of the model, and it may fail to learn or generalize well.\n",
        "\n",
        "Regarding the choice of activation function, different activation functions serve different purposes and are suited to different types of problems:\n",
        "\n",
        "1)Logistic (sigmoid): Traditionally used in MLPs for binary classification problems due to its smooth, differentiable nature. However, it can suffer from the vanishing gradient problem during training.\n",
        "\n",
        "2)ReLU (Rectified Linear Unit): Widely used in deep learning models for its simplicity and effectiveness in combating the vanishing gradient problem. ReLU is often used in hidden layers but not in the output layer for classification tasks, as it allows the network to learn more complex representations.\n",
        "\n",
        "3)Identity: Essentially a linear activation function, it preserves the input as output. It's useful when the output space is unbounded and you want the model to directly predict real values.\n",
        "\n",
        "4)Tanh (Hyperbolic Tangent): Similar to sigmoid but outputs values in the range [-1, 1], making it suitable for models where inputs are also normalized to that range.\n",
        "\n",
        "The choice of activation function depends on the specific characteristics of the problem, such as the nature of the data, the desired output space, and the potential issues like vanishing gradients.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aEZ-8MKGJ2UP"
      }
    }
  ]
}